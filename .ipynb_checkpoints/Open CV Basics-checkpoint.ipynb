{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246cd1d6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759155d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f9b362",
   "metadata": {},
   "source": [
    "## This project contains explanations with examples for different open-cv possible actions.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5095027",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "make format for each area, insert summary, links, etc.</br>\n",
    "add plots for display inside the notebook?</br>\n",
    "explain about open-cv.</br>\n",
    "verify RGB/BGR.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5cb260",
   "metadata": {},
   "source": [
    "## Basic operations\n",
    "### Import, read and display an image or video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c622013",
   "metadata": {},
   "source": [
    "<h4>Image Basics</h4>\n",
    "Read (import) and show an image.</br>\n",
    "The used functions are cv.imread() for reading and importing and cv.imshow() for displaying the image in a new window.</br>\n",
    "View the official documentation for more information:</br>\n",
    "<a href=\"https://docs.opencv.org/3.4/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56\">imread</a></br>\n",
    "<a href=\"https://docs.opencv.org/3.4/d7/dfc/group__highgui.html#ga453d42fe4cb60e5723281a89973ee563\">imshow</a></br>\n",
    "cv.waitKey() is used to set the image show delay to 0.</br>\n",
    "<a href=\"https://docs.opencv.org/3.4/d7/dfc/group__highgui.html#ga5628525ad33f52eab17feebcfba38bd7\">waitKey</a></br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ab091",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy01.jpeg')#Import an image and assign to a variable.\n",
    "cv.imshow('Buddy', img)#Display the image in a new window. set 'Buddy' as the window title.\n",
    "cv.waitKey(0)#Set delay to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f5bf54",
   "metadata": {},
   "source": [
    "<h4>Video Basics</h4>\n",
    "Read (import) and play an existing video.</br>\n",
    "The video is imported and saved in the 'cap' variable using cv.VideoCapture(). View\n",
    "<a href=\"https://docs.opencv.org/3.4/d8/dfe/classcv_1_1VideoCapture.html\">VideoCapture</a></br>\n",
    "The play proccess is using an infinite 'while' loop, with the following flow:</br>\n",
    "1. Frame read: Using the cv.VideoCapture().read() method, a frame is read and assigned to a 'frame' variableand a boolean value is returned to the ret_val variable. View <a href=\"https://docs.opencv.org/3.4/d8/dfe/classcv_1_1VideoCapture.html#a473055e77dd7faa4d26d686226b292c1\">VideoCapture.read</a></br>\n",
    "2. If the read() worked, display the frame in a new window using cv.imshow().\n",
    "3. Check the loop's manual stop condition - if the 'q' key was pressed the loop will break and the play will stop.\n",
    "4. If the read() returned False the loop will break.</br>\n",
    "When the loop ends, we use VideoCapture().release() to release the video capture object and cv.destroyAllWindows()</br>\n",
    "to close all open frames/windows.</br>\n",
    "View:</br>\n",
    "<a href=\"https://docs.opencv.org/3.4/d8/dfe/classcv_1_1VideoCapture.html#afb4ab689e553ba2c8f0fec41b9344ae6\">VideoCapture.release</a></br>\n",
    "<a href=\"https://docs.opencv.org/3.4/d7/dfc/group__highgui.html#ga6b7fc1c1a8960438156912027b38f481\">destroyAllWindows</a></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c45e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture('Resources/Videos/Buddy01.mp4')#Import the video and assign to a variable.\n",
    "while True:\n",
    "    ret_val, frame = cap.read()#Captrure the next frame\n",
    "    if ret_val == True:#If a frame exists\n",
    "        cv.imshow('Buddy Video', frame)#Display the current frame\n",
    "        if cv.waitKey(25) & 0xFF==ord('q'):#Press 'q' key to stop and exit\n",
    "            break\n",
    "    else:#No frame exists, break the loop\n",
    "        break\n",
    "        \n",
    "cap.release()#Release the video capture object\n",
    "cv.destroyAllWindows()#Close all the windows/frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6d9fc3",
   "metadata": {},
   "source": [
    "<h4>Rescale Basics</h4>\n",
    "The below defined function resize_frame() takes a frame and scale (set to default = 75%) as arguments and</br>\n",
    "returns a resized frame using the cv.resize() function.</br>\n",
    "<b>The usage of cv.resize() will be further explored in the more advanced sections</b></br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga47a974309e9102f5f08231edc7e7529d\">resize</a></br>\n",
    "The image height equals to the 'shape 0' value - number of rows and the width to 'shape 1' - number of columns.</br></br>\n",
    "\n",
    "---\n",
    "In the following cells we apply the function to the previous used image and video display algorithms to view the outcome.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd5eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_frame(frame, scale=0.75):\n",
    "    height = int(frame.shape[0]*scale)#Rescale new height\n",
    "    width = int(frame.shape[1]*scale)#Rescale new width\n",
    "    return cv.resize(frame, (width, height), interpolation=cv.INTER_AREA)#Resize and return the resized frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb546ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the original and resized images\n",
    "img = cv.imread('Resources/Photos/Buddy01.jpeg')#Import an image and assign to a variable\n",
    "resized_img = resize_frame(img)#Resize the image using the above created function resize_frame()\n",
    "resized_img2 = resize_frame(img, 0.5)#Resize the image to 50% using the above created function resize_frame()\n",
    "cv.imshow('Buddy', img)#Display the original image in a new window\n",
    "cv.imshow('Buddy Resized', resized_img)#Display the resized image in a new window\n",
    "cv.imshow('Buddy Resized 2', resized_img2)#Display the resized image in a new window\n",
    "\n",
    "cv.waitKey(0)#Set delay to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb146a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the original and resized video\n",
    "cap = cv.VideoCapture('Resources/Videos/Buddy01.mp4')#Import the video and assign to a variable\n",
    "while True:\n",
    "    ret_val, frame = cap.read()#Captrure the next frame\n",
    "    if ret_val == True:#If a frame exists\n",
    "        frame_resized = resize_frame(frame)\n",
    "        cv.imshow('Buddy Video', frame)#Display the original frame\n",
    "        cv.imshow('Buddy Video Resized', frame_resized)#Display the resized frame\n",
    "        if cv.waitKey(25) & 0xFF==ord('q'):#Press 'q' key to stop and exit\n",
    "            break\n",
    "    else:#No frame exists, break the loop\n",
    "        break\n",
    "        \n",
    "cap.release()#Release the video capture object\n",
    "cv.destroyAllWindows()#Close all the windows/frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a45fc",
   "metadata": {},
   "source": [
    "## Draw, paint and text basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de77f7d",
   "metadata": {},
   "source": [
    "<h4>Canvas creation</h4>\n",
    "The function create_canvas() implemented below creates and returns a new blac/white canvas to be assigned to a variable and used.</br>\n",
    "If called as '= create_canvas()' the function will return a new 300X300 sized white canvas.</br>\n",
    "The function accepts width and height parameters and any 3<sup>rd</sup> arguments will cause the returned canvas to be black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a74b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Canvas creation function\n",
    "def create_canvas(width=300, height=300, colour=\"white\"):\n",
    "    if colour == \"white\":\n",
    "        return np.full((int(width),int(height),3),255, dtype = 'uint8')#Create a white canvas using a numpy array, sized 300X300.\n",
    "    else:\n",
    "        return np.zeros((int(width),int(height),3), dtype = 'uint8')#Create a black canvas using a numpy array, sized 300X300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5dcc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic image painting - canvas creation\n",
    "black_canvas = create_canvas(250,250,\"black\")\n",
    "cv.imshow('Black canvas', black_canvas)\n",
    "white_canvas = create_canvas()\n",
    "cv.imshow('White canvas', white_canvas)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf494d",
   "metadata": {},
   "source": [
    "<h4>Single colour painting</h4>\n",
    "The cell below demonstrates a single colour painting.</br>\n",
    "By defining the entire canvas cell values to be any single color B/G/R value we can paint the entire canvas.</br>\n",
    "Try different B,G,R combinations (0-255 each) to test different colours.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4de8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic image painting - one color canvas painting\n",
    "canvas = create_canvas()\n",
    "canvas[:] = 0,0,255\n",
    "cv.imshow('Red Canvas', canvas)\n",
    "canvas[:] = 0,255,0\n",
    "cv.imshow('Green Canvas', canvas)\n",
    "canvas[:] = 255,0,0\n",
    "cv.imshow('Blue Canvas', canvas)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5790a8b",
   "metadata": {},
   "source": [
    "<h4>Horizontal/vertical painting</h4>\n",
    "The cell below presents different horizontal/vertical black and white painting combinations.</br>\n",
    "In those examples the canvas was divided as 50-50. Change the indexing to try different combinations.</br>\n",
    "Change the assigned values (B,G,R) to check different colour combinations.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e0b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic image painting - shape painting\n",
    "# Horizontal\n",
    "canvas = create_canvas()\n",
    "canvas[150:] = 0,0,0#Set all rows > 150 to value 0,0,0 -> black colour\n",
    "cv.imshow('White and black horizontal split', canvas)\n",
    "canvas[0:150] = 0,0,0#Set all rows < 150 to value 0,0,0 -> black colour\n",
    "canvas[150:] = 255,255,255#Set all rows > 150 to value 255,255,255 -> white colour\n",
    "cv.imshow('Black and white horizontal split', canvas)\n",
    "# Vertical\n",
    "canvas = create_canvas()\n",
    "canvas[:,150:] = 0,0,0#Set all columns > 150 to value 0,0,0 -> black colour\n",
    "cv.imshow('White and black vertical split', canvas)\n",
    "canvas[:,0:150] = 0,0,0#Set all rows < 150 to value 0,0,0 -> black colour\n",
    "canvas[:,150:] = 255,255,255#Set all rows > 150 to value 255,255,255 -> white colour\n",
    "cv.imshow('Black and white vertical split', canvas)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09052367",
   "metadata": {},
   "source": [
    "<h4>Open CV shapes</h4>\n",
    "This section contains different shapes painted using different open-cv functions.</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d6/d6e/group__imgproc__draw.html#ga7078a9fae8c7e7d13d24dac2520ae4a2\">line</a></br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d6/d6e/group__imgproc__draw.html#ga07d2f74cadcf8e305e810ce8eed13bc9\">rectangle</a></br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d6/d6e/group__imgproc__draw.html#gaf10604b069374903dbd0f0488cb43670\">circle</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab69f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line\n",
    "canvas = create_canvas()\n",
    "cv.line(canvas, (0,0), (canvas.shape[1]//2,canvas.shape[0]//2), (0,0,0), thickness=5)#Create a diagonal line, starting at (0,0), spreading to the center with thickness=5 px\n",
    "cv.imshow('Diagonal line', canvas)\n",
    "canvas = create_canvas()\n",
    "cv.line(canvas, (canvas.shape[1]//2,0), (canvas.shape[1]//2,canvas.shape[0]), (0,0,0), thickness=5)#Create a diagonal line, starting at (0,0), spreading to the center with thickness=5 px\n",
    "cv.imshow('Vertical center line', canvas)\n",
    "canvas = create_canvas()\n",
    "cv.line(canvas, (0,canvas.shape[0]//2), (canvas.shape[1],canvas.shape[0]//2), (0,0,0), thickness=5)#Create a diagonal line, starting at (0,0), spreading to the center with thickness=5 px\n",
    "cv.imshow('Horizontal center line', canvas)\n",
    "canvas = create_canvas()\n",
    "cv.line(canvas, (canvas.shape[1]//2,0), (canvas.shape[1]//2,canvas.shape[0]), (0,0,0), thickness=5)#Create a diagonal line, starting at (0,0), spreading to the center with thickness=5 px\n",
    "cv.line(canvas, (0,canvas.shape[0]//2), (canvas.shape[1],canvas.shape[0]//2), (0,0,0), thickness=5)#Create a diagonal line, starting at (0,0), spreading to the center with thickness=5 px\n",
    "cv.imshow('Cross', canvas)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d05499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty rectrangle\n",
    "canvas = create_canvas()\n",
    "cv.rectangle(canvas, (0,0), (canvas.shape[1]//2,canvas.shape[0]//2), (0,0,0), thickness=1)#Create a rectangle, starting at (0,0), spreading to (150,150) with a thickness of 1 px\n",
    "cv.imshow('Basic black rectangle', canvas)\n",
    "canvas = create_canvas()\n",
    "cv.rectangle(canvas, (canvas.shape[1]//2,canvas.shape[0]//2), (canvas.shape[1],canvas.shape[0]), (0,0,0), thickness=1)#Create a rectangle, starting at (0,0), spreading to (150,150) with a thickness of 1 px\n",
    "cv.imshow('Basic black rectangle 2', canvas)\n",
    "canvas = create_canvas()\n",
    "cv.rectangle(canvas, (100,100), (200,200), (0,0,0), thickness=2)#Create a rectangle around the center with a thickness of 2 px\n",
    "cv.imshow('Centered black rectangle', canvas)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7193f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filled rectrangle\n",
    "canvas = create_canvas()\n",
    "cv.rectangle(canvas, (0,0), (canvas.shape[1]//2,canvas.shape[0]//2), (0,0,0), thickness=cv.FILLED)#Create a filled rectangle, starting at (0,0), spreading to (150,150)\n",
    "cv.imshow('Basic black rectangle', canvas)\n",
    "canvas = create_canvas()\n",
    "cv.rectangle(canvas, (canvas.shape[1]//2,canvas.shape[0]//2), (canvas.shape[1],canvas.shape[0]), (0,0,0), thickness=cv.FILLED)#Create a filled rectangle, starting at (0,0), spreading to (150,150)\n",
    "canvas = create_canvas()\n",
    "cv.rectangle(canvas, (100,100), (200,200), (0,0,0), thickness=cv.FILLED)#Create a filled rectangle around the center\n",
    "cv.imshow('Centered black rectangle', canvas)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b108d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty circle\n",
    "canvas = create_canvas()\n",
    "cv.circle(canvas, (canvas.shape[1]//2,canvas.shape[0]//2), 10, (0,0,0), thickness=1)#Create a circle around the center, radius = 10, thickness of 1 px\n",
    "cv.imshow('Circle 1', canvas)\n",
    "canvas = create_canvas()\n",
    "cv.circle(canvas, (canvas.shape[1]//2,canvas.shape[0]//2), 50, (0,0,0), thickness=2)#Create a circle around the center, radius = 50, thickness of 2 px\n",
    "cv.imshow('Circle 2', canvas)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c03cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filled circle\n",
    "canvas = create_canvas()\n",
    "cv.circle(canvas, (canvas.shape[1]//2,canvas.shape[0]//2), 10, (0,0,0), thickness=cv.FILLED)#Create a filled circle around the center, radius = 10\n",
    "cv.imshow('Circle 1', canvas)\n",
    "canvas = create_canvas()\n",
    "cv.circle(canvas, (canvas.shape[1]//2,canvas.shape[0]//2), 50, (0,0,0), thickness=cv.FILLED)#Create a filled circle around the center, radius = 50\n",
    "cv.imshow('Circle 2', canvas)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16cd97a",
   "metadata": {},
   "source": [
    "<h4>Circles pattern</h4>\n",
    "In this cell we draw mutliple circles as a pattern.</br>\n",
    "We use numpy.linspace() to create an array of integers to be used as radiuses.</br>\n",
    "View <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.linspace.html\">numpy.linspace</a></br>\n",
    "The array will contain integers between 10 to 100 with a jump of 10.</br>\n",
    "To create the pattern we loop through the radiuses array and add a new circle with each radius to the canvas.</br>\n",
    "Change the circles to any other shape (rectangle, etc.) by changing the cv.circle() function to another one of choise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = create_canvas()\n",
    "radiuses = np.linspace(10,100,10, dtype=int)#Create radius array, 10 points between 10 and 100\n",
    "for radius in radiuses:\n",
    "    cv.circle(canvas, (canvas.shape[1]//2,canvas.shape[0]//2), radius, (0,0,0), thickness=1)#Create a circle around the center, radius changes, thickness of 1 px\n",
    "cv.imshow('Circles', canvas)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc2866",
   "metadata": {},
   "source": [
    "<h4>Add text to image</h4>\n",
    "The cells below show the basic method of writing text to an image with different examples.</br>\n",
    "Adding the text using the cv.putText() function</br>\n",
    "Change the content (string), Point (first tuple), font (cv.FONT_HERSHEY_*), colour (second tuple), scale (double) and thickness (integer) to modify the added text)</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d6/d6e/group__imgproc__draw.html#ga5126f47f883d730f633d74f07456c576\">putText</a></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af2b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = create_canvas()\n",
    "cv.putText(canvas, 'Hello World!', (50,50), cv.FONT_HERSHEY_SIMPLEX, 1.0, 2)#Add the text 'Hello World!' starting at (50,50) with a thickness of 2 px\n",
    "cv.imshow('Hello World!', canvas)\n",
    "canvas = create_canvas()\n",
    "cv.putText(canvas, 'Hello World!', (50,200), cv.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 2)#Add the text 'Hello World!' starting at (50,200) with a red colour thickness of 2 px\n",
    "cv.imshow('Hello World! low red', canvas)\n",
    "canvas = create_canvas()\n",
    "cv.putText(canvas, 'Hello World!', (50,50), cv.FONT_HERSHEY_SIMPLEX, 0.5, 5)#Add the text 'Hello World!' starting at (50,50), scaled to 50% with a thickness of 5 px\n",
    "cv.imshow('Hello World! small', canvas)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbd68db",
   "metadata": {},
   "source": [
    "## Basic Image Manipulation\n",
    "The following section contain different basic image manipulation methods.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abf102a",
   "metadata": {},
   "source": [
    "<h4>Convert a coloured image to grayscale</h4>\n",
    "The next cell imports an image and converts it to grayscale.</br>\n",
    "There are many algorithms that require the usage of grayscale images as input, which makes this function very important to know.</br>\n",
    "We use the cv.imread() function to import and the cv.cvtColor() with the 'cv.COLOR_BGR2GRAY' integer code to convert to grayscale.</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab\">cvtColor</a></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy02.jpeg')#Import an image and assign to a variable.\n",
    "gray_image = cv.cvtColor(img, cv.COLOR_BGR2GRAY)#Convert to grayscale\n",
    "cv.imshow('Original Buddy', img)\n",
    "cv.imshow('Gray Buddy', gray_image)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc273a3e",
   "metadata": {},
   "source": [
    "<h4>Trheshold image</h4>\n",
    "Some algorithms require a binary representation of an image (complete black or white).</br>\n",
    "For that, we convert a grayscale image to binary by a certain threhold using the cv.threshold() function.</br>\n",
    "The function takes the image,  a threshold value, the max value to be used and a threshold type.</br>\n",
    "Different threshold values will affect the seperation/division.</br>\n",
    "Below are examples of binary and inverted binary threshold types, each with 2 different threshold values.</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57\">threshold</a></br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d7/d1b/group__imgproc__misc.html#gaa9e58d2860d4afa658ef70a9b1115576\n",
    "\">threshold types</a></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b4bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy01.jpeg', cv.IMREAD_GRAYSCALE)#Import an image, convert to grayscale and assigne to a variable\n",
    "cv.imshow('Gray Buddy', img)\n",
    "th1, threshold_binary = cv.threshold(img, 150, 255, cv.THRESH_BINARY)#Create a binary image with a threshold of 150 using THRESH_BINARY\n",
    "cv.imshow('Threshold binary th=150', threshold_binary)\n",
    "th1, threshold_binary = cv.threshold(img, 100, 255, cv.THRESH_BINARY)#Create a binary image with a threshold of 100 using THRESH_BINARY\n",
    "cv.imshow('Threshold binary th=100', threshold_binary)\n",
    "th2, threshold_binary_inverted = cv.threshold(img, 150, 255, cv.THRESH_BINARY_INV)#Create a binary image with a threshold of 150 using THRESH_BINARY_INV\n",
    "cv.imshow('Threshold binary inverted th=150', threshold_binary_inverted)\n",
    "th2, threshold_binary_inverted = cv.threshold(img, 100, 255, cv.THRESH_BINARY_INV)#Create a binary image with a threshold of 100 using THRESH_BINARY_INV\n",
    "cv.imshow('Threshold binary inverted th=100', threshold_binary_inverted)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b35c10a",
   "metadata": {},
   "source": [
    "<h4>Blur image</h4>\n",
    "Blur an image using cv.GaussianBlur().</br>\n",
    "The bigger (positive, odd) Size (first tuple) passed as an argument - the more blurry the image will be.</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1\">GaussianBlur</a></br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f519f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy02.jpeg')#Import an image and assign to a variable.\n",
    "blur_image = cv.GaussianBlur(img, (3,3), cv.BORDER_DEFAULT)#Blur with a kernel size of (3,3)\n",
    "blurrer_image = cv.GaussianBlur(img, (9,9), cv.BORDER_DEFAULT)#Blur with a kernel size of (9,9)\n",
    "cv.imshow('Original Buddy', img)\n",
    "cv.imshow('Blur Buddy', blur_image)\n",
    "cv.imshow('Blurrer Buddy', blurrer_image)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45fcf6d",
   "metadata": {},
   "source": [
    "<h4>Edge detection</h4>\n",
    "Edge detection in an image can be very helpful.</br>\n",
    "In this example I used the cv.Canny() function that uses the Canny edge detector algorithm to detecte the edges.</br>\n",
    "View <a href=\"https://en.wikipedia.org/wiki/Canny_edge_detector\">Canny edge detection algorithm (Wikipedia)</a></br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de\">Canny</a></br>\n",
    "cv.Canny() takes 3 arguments. The first one is the image and the other two are 2 thresholds used for a step from the Canny</br>\n",
    "algorithm. Changing the threshold will affect the sensitivity of the edge detection algorithm.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e63f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy02.jpeg')#Import an image and assign to a variable.\n",
    "canny_100 = cv.Canny(img, 100, 200)#Find the edges using 100 as a threshold\n",
    "canny_200 = cv.Canny(img, 200, 300)#Find the edges using 200 as a threshold\n",
    "cv.imshow('Original Buddy', img)\n",
    "cv.imshow('Canny edges (100, 200)', canny_100)\n",
    "cv.imshow('Canny edges (200, 300)', canny_200)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf5089",
   "metadata": {},
   "source": [
    "##  Morphological Transformations\n",
    "<h3>Below are implementaions and examples of dilation and erosion, two of operations of binary morphology</h3>\n",
    "View <a href=\"https://en.wikipedia.org/wiki/Mathematical_morphology\">Mathematical morphology (Wikipedia)</a></br>\n",
    "View <a href=\"https://en.wikipedia.org/wiki/Dilation_(morphology)\">Dilation (Wikipedia)</a></br>\n",
    "View <a href=\"https://en.wikipedia.org/wiki/Erosion_(morphology)\">Erosion (Wikipedia)</a></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f515eb",
   "metadata": {},
   "source": [
    "<h4>Dilation</h4>\n",
    "To apply dilation on binary images we use the cv.dilate() function.</br>\n",
    "The function takes the image, a structuring image (kernel) and the number of iterations to repeat as arguments.</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#ga4ff0f3318642c4f469d0e11f242f3b6c\">dilate</a></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff367e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy03.jpeg', cv.IMREAD_GRAYSCALE)#Import an image, convert to grayscale and assigne to a variable\n",
    "th1, threshold_binary_image = cv.threshold(img, 125, 255, cv.THRESH_BINARY)\n",
    "cv.imshow('Binary Buddy', threshold_binary_image)\n",
    "dilated_33_1 = cv.dilate(threshold_binary_image, (3,3), iterations=1)\n",
    "cv.imshow('Dilated kernel 3x3, 1 iteration Buddy', dilated_33_1)\n",
    "dilated_33_3 = cv.dilate(threshold_binary_image, (3,3), iterations=3)\n",
    "cv.imshow('Dilated kernel 3x3, 3 iterations Buddy', dilated_33_3)\n",
    "dilated_55_1 = cv.dilate(threshold_binary_image, (5,5), iterations=1)\n",
    "cv.imshow('Dilated kernel 5x5, 1 iteration Buddy', dilated_55_1)\n",
    "dilated_55_4 = cv.dilate(threshold_binary_image, (5,5), iterations=4)\n",
    "cv.imshow('Dilated kernel 5x5, 4 iterations Buddy', dilated_55_4)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3a04d",
   "metadata": {},
   "source": [
    "<h4>Erosion</h4>\n",
    "To apply erosion on binary images we use the cv.erode() function.</br>\n",
    "The function takes the image, a structuring image (kernel) and the number of iterations to repeat as arguments.</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb\">erode</a></br>\n",
    "Below there are several images shown:</br>\n",
    "1. A canny image of Buddy</br>\n",
    "2. A dilated image of Buddy</br>\n",
    "3. Two Eroded images of the dilated image of Buddy</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406da737",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy03.jpeg', cv.IMREAD_GRAYSCALE)#Import an image, convert to grayscale and assign to a variable\n",
    "canny_100 = cv.Canny(img, 100, 200)#Find the edges using 100 as a threshold\n",
    "cv.imshow('Canny Buddy', canny_100)\n",
    "dilated_33_3 = cv.dilate(canny_100, (3,3), iterations=3)\n",
    "cv.imshow('Dilated kernel 3x3, 3 iterations Buddy', dilated_33_3)\n",
    "eroded_33_1 = cv.erode(dilated_33_3, (3,3), iterations=1)\n",
    "cv.imshow('Eroded kernel 3x3, 1 iteration Buddy', eroded_33_1)\n",
    "eroded_33_3 = cv.erode(dilated_33_3, (3,3), iterations=3)\n",
    "cv.imshow('Eroded kernel 3x3, 3 iterations Buddy', eroded_33_3)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b80609f",
   "metadata": {},
   "source": [
    "## Basic image transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731051bb",
   "metadata": {},
   "source": [
    "<h4>Resize</h4>\n",
    "Below are some advanced usages of cv.resize().</br>\n",
    "The interpolation is changed on different scenarios, we mostly use cv.INTER_AREA when reducing the size and INTER_LINEAR when increasing to improve quality.</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#gga5bb5a1fea74ea38e1a5445ca803ff121acf959dca2480cc694ca016b81b442ceb\">interpolaion</a></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2639e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy03.jpeg')#Import an image and assigne to a variable\n",
    "resized_200_200_image = cv.resize(img, (200,200), interpolation = cv.INTER_AREA)#Reduce the image size to 200x200\n",
    "cv.imshow('200x200 resized Buddy', resized_200_200_image)\n",
    "resized_800_800_image_area = cv.resize(resized_200_200_image, (800,800), interpolation = cv.INTER_AREA)#Increase size to 800x800 using cv.INTER_AREA for interpolation\n",
    "cv.imshow('800x800 resized bigger Buddy INTER_AREA', resized_800_800_image_area)\n",
    "resized_800_800_image_linear = cv.resize(resized_200_200_image, (800,800), interpolation = cv.INTER_LINEAR )#Increase size to 800x800 using cv.INTER_LINEAR for interpolation\n",
    "cv.imshow('800x800 resized bigger Buddy INTER_LINEAR', resized_800_800_image_linear)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247ab58b",
   "metadata": {},
   "source": [
    "<h4>Crop</h4>\n",
    "Each imported image is saved as an integer array.</br>\n",
    "To crop the image/array we can use regular 2-D matrix manipulation techniques.</br>\n",
    "Pay attention that an image is stored differently in python than in mathematics:</br>\n",
    "-The 'X' axe is positive from left to right.</br>\n",
    "-The 'Y' axe is positive downwards (opposed to familiared mathematics and geometry).</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56\">imread</a></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy02.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//2,img.shape[0]//2))\n",
    "cv.imshow('Resized Buddy', img)\n",
    "left_half_cropped = img[:,0:img.shape[1]//2]\n",
    "cv.imshow('Left cropped Buddy', left_half_cropped)\n",
    "right_half_cropped = img[:,img.shape[1]//2:]\n",
    "cv.imshow('Right cropped Buddy', right_half_cropped)\n",
    "random_crop = img[150:450,110:450]\n",
    "cv.imshow('Random cropped Buddy', random_crop)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286f75cb",
   "metadata": {},
   "source": [
    "<h4>Shifting/translation</h4>\n",
    "As mentioned before, the axes in python behave different than in mathematics.</br>\n",
    "To shift an image we must follow these rules:</br>\n",
    "1. Shift right => x++</br>\n",
    "2. Shift left => x--</br>\n",
    "3. Shift down => y++</br>\n",
    "4. Shift up => y--<br>\n",
    "The shift is made using cv.warpAffine() function.</br>\n",
    "The function takes the image, a transformation matrix sized 2x3. Changing the values in the transform matrix will cause different shifting/transformations, and the image dimensions as arguments.</br>\n",
    "Below we shift linearly - right, left, up, down, so that the 3<sup>rd</sup> value in each list is the amount of shift.</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga0203d9ee5fcd28d40dbc4a1ea4451983\">warpAffine</a></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa343dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy03.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//2,img.shape[0]//2))\n",
    "cv.imshow('Original Buddy', img)\n",
    "translation_matrix = np.float32([[1,0,100],[0,1,100]])\n",
    "shifted_p100_p100 = cv.warpAffine(img, translation_matrix, (img.shape[1],img.shape[0]))\n",
    "cv.imshow('Shifted Buddy +100, +100', shifted_p100_p100)\n",
    "translation_matrix = np.float32([[1,0,-50],[0,1,75]])\n",
    "shifted_m150_p75 = cv.warpAffine(img, translation_matrix, (img.shape[1],img.shape[0]))\n",
    "cv.imshow('Shifted Buddy -50, +75', shifted_m150_p75)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86699860",
   "metadata": {},
   "source": [
    "<h4>Rotation</h4>\n",
    "Rotating an image can be very important to various purposes, including ML/AI.</br>\n",
    "The image rotation below is made using the cv.getRotationMatrix2D() function to create the new rotation matrix.</br>\n",
    "The function gets the rotation point (first tuple, in this case the center), the rotation angle (integer) and the scale (floating point, here set to 1.0 for no image scaling).</br>\n",
    "Change each value to view the outcome.</br>\n",
    "The transformation is made using the previously used cv.warpAffine() function with the new rotation matrix as the transformation matrix.</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#gafbbc470ce83812914a70abfb604f4326\">getRotationMatrix2D</a></br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga0203d9ee5fcd28d40dbc4a1ea4451983\">warpAffine</a></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db861946",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy04.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//3,img.shape[0]//3))\n",
    "angles = [45,90,135,180]\n",
    "for angle in angles:\n",
    "    rotation_matrix = cv.getRotationMatrix2D((img.shape[1]//2,img.shape[0]//2), angle, 1.0)\n",
    "    rotated_image = cv.warpAffine(img, rotation_matrix, (img.shape[1], img.shape[0]))\n",
    "    cv.imshow(f'Rotated Buddy by {angle}', rotated_image)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed143bfb",
   "metadata": {},
   "source": [
    "<h4>Flipping</h4>\n",
    "Some algorithms require mirrored image to process, for chaining and for other reasons.</br>\n",
    "We use the cv.flip() function to flip an image.</br>\n",
    "The cv.flip() takes the image to be flipped and a flipCode (-1 = flip vertical and horizontal, 0 = flip vertical, 1 = flip horizontal).</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d2/de8/group__core__array.html#gaca7be533e3dac7feb70fc60635adf441\">flip</a></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy04.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//3,img.shape[0]//3))\n",
    "cv.imshow('Original Buddy', img)\n",
    "flips = [-1, 0, 1]\n",
    "titles = ['Horizontal & Vertical', 'Vertical', 'Horizontal']\n",
    "for i in range(3):\n",
    "    flip = cv.flip(img, flips[i])\n",
    "    cv.imshow(f'{titles[i]} flip using flipCode = {flips[i]}', flip)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d385ba",
   "metadata": {},
   "source": [
    "<h4>Basic contour detection</h4>\n",
    "Contours are a continous curve along the boundary of an object that have the same colour or intensity.</br>\n",
    "Contours are often used in object detection and recognition by applying different masking functions to isolate different parts of an image.</br>\n",
    "To improve accuracy we use binary images. In the example below I have applied cv.canny() on the image but any other method can be used (such as cv.threshold() displayed above).</br>\n",
    "The function used to find the contours is cv.findContours() that takes the image, the contour retrieval mode and the contour approximation method and outputs the modified image, the contours (a 2d numpy array of the (x,y) of each contour) and the hierarchy (more advanced, will be treated later).</br>\n",
    "In the first cell below there are 2 examples that can show the difference of detecting contours betweep a sharp and blurry image. See the change in the print output.</br>\n",
    "The second cell shows a way of drawing/visualizing the contours in an image using the cv.drawContours() function that takes the contours list, colour and thickness and draws the edges found on a new canvas.</br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga17ed9f5d79ae97bd4c7cf18403e1689a\">findContours</a></br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d6/d6e/group__imgproc__draw.html#ga746c0625f1781f1ffc9056259103edbc\">drawContours</a></br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e757bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy03.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//3,img.shape[0]//3))\n",
    "gray_image = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "blur_gray_image = cv.GaussianBlur(gray_image, (5,5), cv.BORDER_DEFAULT)\n",
    "cv.imshow('Original Buddy', gray_image)\n",
    "cv.imshow('Blur Buddy', blur_gray_image)\n",
    "#\n",
    "canny_100 = cv.Canny(gray_image, 100, 200)#Find the edges using 100 as a threshold\n",
    "cv.imshow('Canny Buddy', canny_100)\n",
    "contours, hierarchy = cv.findContours(canny_100, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "print(f'{len(contours)} cotnours found for the original grayscale image')\n",
    "#\n",
    "canny_100 = cv.Canny(blur_gray_image, 100, 200)#Find the edges using 100 as a threshold\n",
    "cv.imshow('Canny blurred Buddy', canny_100)\n",
    "contours, hierarchy = cv.findContours(canny_100, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "print(f'{len(contours)} cotnours found for the original grayscale image')\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b2ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy03.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//2,img.shape[0]//2))\n",
    "gray_image = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Original Buddy', gray_image)\n",
    "#\n",
    "canny_100 = cv.Canny(gray_image, 100, 200)#Find the edges using 100 as a threshold\n",
    "cv.imshow('Canny Buddy', canny_100)\n",
    "contours, hierarchy = cv.findContours(canny_100, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "#\n",
    "canvas = create_canvas(canny_100.shape[0], canny_100.shape[1], \"black\")\n",
    "cv.drawContours(canvas, contours, -1, (255,0,0),1)\n",
    "cv.imshow('Canvas', canvas)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf67193e",
   "metadata": {},
   "source": [
    "<h2>Color spaces</h2>\n",
    "Much can be explained about color spaces in Open-CV.</br>\n",
    "The default color space used in OpenCV is a formatted RGB - BGR (blue, green, red).</br>\n",
    "Below are some examples containing conversions and usages of different color spaces.\n",
    "\n",
    "---\n",
    "Below are some links to improve the understanding in that topic.</br>\n",
    "View <a href=\"https://docs.opencv.org/4.x/df/d9d/tutorial_py_colorspaces.html\">opencv.org</a></br>\n",
    "View <a href=\"https://learnopencv.com/color-spaces-in-opencv-cpp-python/\">LearnOpenCV.com</a></br>\n",
    "View <a href=\"https://www.geeksforgeeks.org/color-spaces-in-opencv-python/\">GeeksForGeeks.org</a></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e33605",
   "metadata": {},
   "source": [
    "<h4>BGR vs RGB</h4>\n",
    "Open-CV uses BGR format while most other use RGB.</br>\n",
    "Below desplayed the differences between RGB and BGR formatted images, displayed with Open-CV and Matplotlib.</br>\n",
    "View <a href=\"https://matplotlib.org/3.5.1/api/_as_gen/matplotlib.pyplot.subplots.html\">Matplotlib subplots</a></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f713c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy07.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//2,img.shape[0]//2))\n",
    "rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "#\n",
    "cv.imshow('BGR Buddy', img)\n",
    "cv.imshow('RGB Buddy', rgb)\n",
    "#\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(img)\n",
    "axs[1].imshow(rgb)\n",
    "axs[0].title.set_text('BGR')\n",
    "axs[1].title.set_text('RGB')\n",
    "plt.show()\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2abb00",
   "metadata": {},
   "source": [
    "<h4>BGR to ___ conversions</h4>\n",
    "Below are some different conversions using the cv.cvtColor() function used with different conversion codes to get different outputs.</br>\n",
    "View <a href=\"https://docs.opencv.org/4.x/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab\">cvtColor</a></br>\n",
    "View <a href=\"https://docs.opencv.org/4.x/d8/d01/group__imgproc__color__conversions.html#ga4e0972be5de079fed4e3a10e24ef5ef0\">ColorConversionCodes</a></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ee1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy07.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//2,img.shape[0]//2))\n",
    "cv.imshow('BGR Buddy', img)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray Buddy', gray)\n",
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "cv.imshow('HSV Buddy', hsv)\n",
    "luv = cv.cvtColor(img, cv.COLOR_BGR2Luv)\n",
    "cv.imshow('luv Buddy', luv)\n",
    "lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "cv.imshow('lab Buddy', lab)\n",
    "rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "cv.imshow('RGB Buddy', rgb)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1325a3e",
   "metadata": {},
   "source": [
    "<h4>___ to BGR conversions</h4>\n",
    "Conversion from/to BGR is simple and straight-forward using the cv.cvtColor() function.</br>\n",
    "Conversion between different color spaces is more complicated and require using BGR as a link. For example:</br>\n",
    "To convert grayscale to hsv we need to convert the grayscale to BGR and the BGR to hsv.</br>\n",
    "Below are some examples of reverse conversions - converting <b>to BGR</b>.</br>\n",
    "View <a href=\"https://docs.opencv.org/4.x/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab\">cvtColor</a></br>\n",
    "View <a href=\"https://docs.opencv.org/4.x/d8/d01/group__imgproc__color__conversions.html#ga4e0972be5de079fed4e3a10e24ef5ef0\">ColorConversionCodes</a></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62790a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the different color space images to convert from\n",
    "img = cv.imread('Resources/Photos/Buddy08.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//2,img.shape[0]//2))\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "luv = cv.cvtColor(img, cv.COLOR_BGR2Luv)\n",
    "lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "#Conversion of each to BGR\n",
    "gray_bgr = cv.cvtColor(gray, cv.COLOR_GRAY2BGR)\n",
    "hsv_bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "luv_bgr = cv.cvtColor(luv, cv.COLOR_Luv2BGR)\n",
    "lab_bgr = cv.cvtColor(lab, cv.COLOR_LAB2BGR)\n",
    "rgb_bgr = cv.cvtColor(rgb, cv.COLOR_RGB2BGR)\n",
    "cv.imshow('Grayscale to bgr', gray_bgr)\n",
    "cv.imshow('HSV to bgr', hsv_bgr)\n",
    "cv.imshow('Luv to bgr', luv_bgr)\n",
    "cv.imshow('LAB to bgr', lab_bgr)\n",
    "cv.imshow('RGB to bgr', rgb_bgr)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884e0e49",
   "metadata": {},
   "source": [
    "<h4>Channel split</h4>\n",
    "Splitting to different RGB/BGR channels can help in alazyzing specific areas/sections/colors of the image and in different conversions (if needed to use RGB instead of BGR for example).</br>\n",
    "Below I used the cv.split() function to split the image in to 3 different channels - b, g, r for blue, green, red.</br>\n",
    "You can see the difference of the intensity in different areas where the original image had stronger and more obselete values for red/green/blue.</br>\n",
    "The function cv.merge() is used to merge the seperate channels into one by an order (b,g,r for BGR and r,g,b for RGB).</br>\n",
    "View <a href=\"https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga8027f9deee1e42716be8039e5863fbd9\">split</a></br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d2/de8/group__core__array.html#ga61f2f2bde4a0a0154b2333ea504fab1d\">merge</a></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c218fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy07.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//2,img.shape[0]//2))\n",
    "#Split channels to b=blue, g=green, r=red\n",
    "b, g, r = cv.split(img)\n",
    "cv.imshow(\"Original\", img)\n",
    "cv.imshow(\"Blue intensity\", b)\n",
    "cv.imshow(\"Green intensity\", g)\n",
    "cv.imshow(\"Red intensity\", r)\n",
    "#Merge channels to BGR/RGB\n",
    "merged_bgr = cv.merge([b,g,r])\n",
    "merged_rgb = cv.merge([r,g,b])\n",
    "cv.imshow(\"Merged BGR\", merged_bgr)\n",
    "cv.imshow(\"Merged RGB\", merged_rgb)\n",
    "#Display one channel only\n",
    "canvas = np.zeros(img.shape[:2], dtype = 'uint8')\n",
    "blue_image = cv.merge([b,canvas,canvas])\n",
    "green_image = cv.merge([canvas,g,canvas])\n",
    "red_image = cv.merge([canvas,canvas,r])\n",
    "cv.imshow(\"Merged blue\", blue_image)\n",
    "cv.imshow(\"Merged green\", green_image)\n",
    "cv.imshow(\"Merged red\", red_image)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb405bb",
   "metadata": {},
   "source": [
    "<h2>Advanced bluring/smoothing</h2>\n",
    "Image blurring is achieved by convolving the image with a low-pass filter kernel. It is useful for removing noise.</br>\n",
    "Different blur algorithms provide different results, some are sharper, some enhance object seperation and edges and each has its own usage.</br>\n",
    "The cells below demonstrate the use of different blur algorithms/functions and the last cell contains a comparison of different blur applied on the same image.</br>\n",
    "\n",
    "---\n",
    "View <a href=\"https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html\">Open-CV Smoothing Images</a></br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#ga8c45db9afe636703801b0b2e440fce37\">blur</a></br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1\">GaussianBlur</a></br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#ga564869aa33e58769b4469101aac458f9\">medianBlur</a></br>\n",
    "View <a href=\"https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#ga9d7064d478c95d60003cf839430737ed\">bilateralFilter</a></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32c0e9f",
   "metadata": {},
   "source": [
    "<h4>Average blur</h4>\n",
    "Averaging is done by convulving an image with a normalized box filter (kernel).</br>\n",
    "That method takes the average around the central element in a kernel area and replace the center with the average.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e30f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy09.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//2,img.shape[0]//2))\n",
    "average_blur_3_3 = cv.blur(img, (3,3))\n",
    "average_blur_5_5 = cv.blur(img, (5,5))\n",
    "cv.imshow(\"Original Buddy\", img)\n",
    "cv.imshow(\"Average blur 3x3 Buddy\", average_blur_3_3)\n",
    "cv.imshow(\"Average blur 5x5 Buddy\", average_blur_5_5)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd3223",
   "metadata": {},
   "source": [
    "<h4>Gaussian blur</h4>\n",
    "Gaussian blur uses a Gaussian kernel instead of the box filter, the standard deviation in the x and y directions and is highly effective in removing Gaussian noise from an image.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3acc7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy09.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//2,img.shape[0]//2))\n",
    "gaussian_blur_3_3 = cv.GaussianBlur(img, (3,3), 0, 0)\n",
    "gaussian_blur_5_5 = cv.GaussianBlur(img, (5,5), 0, 0)\n",
    "cv.imshow(\"Original Buddy\", img)\n",
    "cv.imshow(\"Gaussian blur 3x3 Buddy\", gaussian_blur_3_3)\n",
    "cv.imshow(\"Gaussian blur 5x5 Buddy\", gaussian_blur_5_5)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca64cb",
   "metadata": {},
   "source": [
    "<h4>Median blur</h4>\n",
    "The Median blur takes the median of the pixels under the kernel area instead of the average and replaces the center with that value.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb23cccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy09.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//2,img.shape[0]//2))\n",
    "median_blur_3_3 = cv.medianBlur(img, 3)\n",
    "median_blur_5_5 = cv.medianBlur(img, 5)\n",
    "cv.imshow(\"Original Buddy\", img)\n",
    "cv.imshow(\"Median blur 3x3 Buddy\", median_blur_3_3)\n",
    "cv.imshow(\"Median blur 5x5 Buddy\", median_blur_5_5)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997eb7e7",
   "metadata": {},
   "source": [
    "<h4>Bilateral blur</h4>\n",
    "The Bilateral blur method is hight effective in keeping the edges sharp and the outcome looks very similar to the original image with a more smooth, paint-like background.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0851849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy09.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//2,img.shape[0]//2))\n",
    "bilateral_blur_3 = cv.bilateralFilter(img, 3, 35, 25)\n",
    "bilateral_blur_10 = cv.bilateralFilter(img, 10, 35, 25)\n",
    "cv.imshow(\"Original Buddy\", img)\n",
    "cv.imshow(\"Bilateral blur 3 Buddy\", bilateral_blur_3)\n",
    "cv.imshow(\"Bilateral blur 10 Buddy\", bilateral_blur_10)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856d1c31",
   "metadata": {},
   "source": [
    "<h4>Different blur comparison</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca946b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy08.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//2,img.shape[0]//2))\n",
    "#Average blur\n",
    "average_blur_7_7 = cv.blur(img, (7,7))\n",
    "#Gaussian blur\n",
    "gaussian_blur_7_7 = cv.GaussianBlur(img, (7,7), 0, 0)\n",
    "#Median blur\n",
    "median_blur_7_7 = cv.medianBlur(img, 7)\n",
    "#Bilateral blur\n",
    "bilateral_blur_10 = cv.bilateralFilter(img, 10, 35, 25)\n",
    "#Image show\n",
    "cv.imshow(\"Original Buddy\", img)\n",
    "cv.imshow(\"Average blur 7x7 Buddy\", average_blur_7_7)\n",
    "cv.imshow(\"Gaussian blur 7x7 Buddy\", gaussian_blur_7_7)\n",
    "cv.imshow(\"Median blur 7x7 Buddy\", median_blur_7_7)\n",
    "cv.imshow(\"Bilateral blur 10 Buddy\", bilateral_blur_10)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d5286",
   "metadata": {},
   "source": [
    "<h2>Bitwise operations and operators</h2>\n",
    "Open-CV allows the usage of bitwise operations and operators to manipulate images.</br>\n",
    "We will be using shapes (rectangle, circle) created using the different Open-CV functions to demonstrate the outcome.</br>\n",
    "View <a href=\"https://www.geeksforgeeks.org/arithmetic-operations-on-images-using-opencv-set-2-bitwise-operations-on-binary-images/\">Geeks For Geeks Bitwise Operations on Binary Images</a></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d1db5",
   "metadata": {},
   "source": [
    "<h4>Bitwise AND</h4>\n",
    "Bitwise AND takes only the common/shared regions of several images.</br>\n",
    "View <a href=\"https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga60b4d04b251ba5eb1392c34425497e14\">bitwise_and</a></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd6e1ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canvas = create_canvas(500,500, \"blacl\")\n",
    "#Filled rectrangle\n",
    "rectangle = cv.rectangle(canvas.copy(), (75,75), (425,425), (255,255,255), thickness=cv.FILLED)#Create a filled rectangle, starting at (0,0), spreading to (150,150)\n",
    "cv.imshow('Rectangle', rectangle)\n",
    "#Filled circle\n",
    "circle = cv.circle(canvas.copy(), (canvas.shape[1]//2,canvas.shape[0]//2), 200, (255,255,255), thickness=cv.FILLED)#Create a filled circle around the center, radius = 10\n",
    "cv.imshow('Circle', circle)\n",
    "rectrangle_and_circle = cv.bitwise_and(rectangle, circle)\n",
    "cv.imshow('Rectangle AND Circle', rectrangle_and_circle)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3928a95",
   "metadata": {},
   "source": [
    "<h4>Bitwise OR</h4>\n",
    "Bitwise OR combines several images.</br>\n",
    "View <a href=\"https://docs.opencv.org/4.x/d2/de8/group__core__array.html#gab85523db362a4e26ff0c703793a719b4\">bitwise_or</a></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73160374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canvas = create_canvas(500,500, \"black\")\n",
    "#Filled rectrangle\n",
    "rectangle = cv.rectangle(canvas.copy(), (75,75), (425,425), (255,255,255), thickness=cv.FILLED)#Create a filled rectangle, starting at (0,0), spreading to (150,150)\n",
    "cv.imshow('Rectangle', rectangle)\n",
    "#Filled circle\n",
    "circle = cv.circle(canvas.copy(), (canvas.shape[1]//2,canvas.shape[0]//2), 200, (255,255,255), thickness=cv.FILLED)#Create a filled circle around the center, radius = 10\n",
    "cv.imshow('Circle', circle)\n",
    "rectrangle_or_circle = cv.bitwise_or(rectangle, circle)\n",
    "cv.imshow('Rectangle OR Circle', rectrangle_or_circle)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4281810",
   "metadata": {},
   "source": [
    "<h4>Bitwise XOR</h4>\n",
    "Bitwise XOR takes only the non-common/non-shared regions in several images.</br>\n",
    "View <a href=\"https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga84b2d8188ce506593dcc3f8cd00e8e2c\">bitwise_xor</a></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78cbbe57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canvas = create_canvas(500,500, \"black\")\n",
    "#Filled rectrangle\n",
    "rectangle = cv.rectangle(canvas.copy(), (75,75), (425,425), (255,255,255), thickness=cv.FILLED)#Create a filled rectangle, starting at (0,0), spreading to (150,150)\n",
    "cv.imshow('Rectangle', rectangle)\n",
    "#Filled circle\n",
    "circle = cv.circle(canvas.copy(), (canvas.shape[1]//2,canvas.shape[0]//2), 200, (255,255,255), thickness=cv.FILLED)#Create a filled circle around the center, radius = 10\n",
    "cv.imshow('Circle', circle)\n",
    "rectrangle_xor_circle = cv.bitwise_xor(rectangle, circle)\n",
    "cv.imshow('Rectangle OR Circle', rectrangle_xor_circle)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172baa65",
   "metadata": {},
   "source": [
    "<h4>Bitwise NOT</h4>\n",
    "Bitwise NOT inverts binary colours.</br>\n",
    "View <a href=\"https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga0002cf8b418479f4cb49a75442baee2f\">bitwise_not</a></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de66aa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canvas = create_canvas(500,500, \"black\")\n",
    "#Filled circle\n",
    "circle = cv.circle(canvas.copy(), (canvas.shape[1]//2,canvas.shape[0]//2), 200, (255,255,255), thickness=cv.FILLED)#Create a filled circle around the center, radius = 10\n",
    "cv.imshow('Circle', circle)\n",
    "circle_not = cv.bitwise_not(circle)\n",
    "cv.imshow('Circle NOT', circle_not)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998bd39",
   "metadata": {},
   "source": [
    "<h2>Masking</h2>\n",
    "Masking uses bitwise operators to mask (extract) a certain area from an image.</br>\n",
    "You can think of masking as placing an image as a mask ontop of another image and only keeping the masked area.</br>\n",
    "We perform the masking using the cv.bitwise_and() function.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c83711",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Resources/Photos/Buddy06.jpeg')\n",
    "img = cv.resize(img, (img.shape[1]//3,img.shape[0]//3))\n",
    "#Create a mask image\n",
    "canvas = create_canvas(img.shape[0],img.shape[1], \"black\")\n",
    "mask = cv.circle(canvas,(canvas.shape[1]//2,canvas.shape[0]//2), 200, (255,255,255), thickness=cv.FILLED)\n",
    "#Apply the mask using bitwise_and\n",
    "masked_image = cv.bitwise_and(img,mask)\n",
    "cv.imshow(\"Original Buddy\", img)\n",
    "cv.imshow(\"Mask\", mask)\n",
    "cv.imshow(\"Masked Buddy\", masked_image)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a49f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
